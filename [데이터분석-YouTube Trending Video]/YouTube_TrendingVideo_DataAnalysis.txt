#----------------------------------------------------------------------------------------------------------------패키지 설치
install.packages("dplyr")
install.packages("readxl")
install.packages("stringr")
install.packages("lubridate")
install.packages("tidyverse")
install.packages("stringr")
install.packages("rJava")
install.packages("memoise")
install.packages("KoNLP")
install.packages("wordcloud")
install.packages("extrafont")
install.packages(".../path/to/package.tar.gz", type="source", repos=NULL)
install.packages("ggplot2")
devtools::install_github("lchiffon/wordcloud2")

library(wordcloud2)
library(readxl)
library(dplyr)
library(stringr)
library(lubridate)
library(dplyr)
library(readr)        # 파일 읽기 기능 제공 (tidyverse패키지에 포함됨)
library(stringr)      # 문자열 관련 기능 제공 패키지
library(rJava)        # KoNLP가 의존함 (Java기능 호출 패키지)
library(memoise)      # KoNLP가 의존함
library(KoNLP)        # 한글데이터 형태소 분석 패키지 (이름 대소문자 주의)
library(wordcloud)    # 워드클라우드 생성 패키지
library(RColorBrewer) # 색상 제어 패키지
library(extrafont)
library(ggplot2)  
library(descr)
library(tidyverse)


# 시스템의 폰트 파일들중 이름에 D2라는 단어가 포함된 폰트를 R 디렉토리 안으로 복사한다.
# --> 오랜 시간이 걸리더라도 수행할지 여부를 묻는 "y/n" 확인이 필요하면 "y"를 입력 후 엔터
font_import(pattern="NanumGothic.ttf")

# 폰트 로드 --> 운영체제에 맞게 설정하세요.
loadfonts(device="win")       # Windows

fonts <- fonttable()
unique(fonts$FamilyName)

Sys.setenv(JAVA_HOME="C:/Program Files/Java/jre1.8.0_271")

# R 64bit 실행(rstudio 실행도 가능) 

# java, rJava 설치 install.packages("multilinguer")
# 이때 mac 사용자는 데스크탑 비밀번호를 물어봅니다. 입력해줘야 설치가 진행됩니다.
library(multilinguer)
install_jdk()
# 위 함수에서 에러가 발생하면 알려주세요
# https://github.com/mrchypark/multilinguer/issues

# 의존성 패키지 설치
install.packages(c("hash", "tau", "Sejong", "RSQLite", "devtools", "bit", "rex", "lazyeval", "htmlwidgets", "crosstalk", "promises", "later", "sessioninfo", "xopen", "bit64", "blob", "DBI", "memoise", "plogr", "covr", "DT", "rcmdcheck", "rversions"), type = "binary")

# github 버전 설치
install.packages("remotes")
# 64bit 에서만 동작합니다.
remotes::install_github('haven-jeon/KoNLP', upgrade = "never", INSTALL_opts=c("--no-multiarch"))


#----------------------------------------------------------------------------------------------------------------------데이터 전처리

youtube_data <- read.csv("E:/DataMining/Final_youtube_trending_data.csv")
View(youtube_data) #원래 데이터 불러오기

duplicated(youtube_data$video_id) #데이터 중복 검사

duplicated_youtube_data <- youtube_data[!duplicated(youtube_data$video_id),] #중복된 데이터 삭제
View(duplicated_youtube_data) 

duplicated(duplicated_youtube_data$video_id) #중복 제거 이후 데이터 중복검사

#새로운 열 생성
youtube_data$category_name <- ifelse (youtube_data$categoryId==1, "Film & Animation",
                                      ifelse(youtube_data$categoryId==2, "Autos & Vehicles",
                                             ifelse(youtube_data$categoryId==10, "Music",
                                                    ifelse(youtube_data$categoryId==15, "Pets & Animals",
                                                           ifelse(youtube_data$categoryId==17, "Sports",
                                                                  ifelse(youtube_data$categoryId==19, "Travle & Events",
                                                                         ifelse(youtube_data$categoryId==20,"Gaming",
                                                                                ifelse(youtube_data$categoryId==22, "People & Blogs",
                                                                                       ifelse(youtube_data$categoryId==23,"Comedy",
                                                                                              ifelse(youtube_data$categoryId==24, "Entertainment",
                                                                                                     ifelse(youtube_data$categoryId==25, "News & Politics",
                                                                                                            ifelse(youtube_data$categoryId==26, "Howto & Style",
                                                                                                                   ifelse(youtube_data$categoryId==27, "Education",
                                                                                                                          ifelse(youtube_data$categoryId==28, "Science & Technology",
                                                                                                                                 ifelse(youtube_data$categoryId==29, "Nonprofits & Activism","None")))))))))))))))


#좋아요 싫어요 비율
youtube_data$likes_dislikes <- youtube_data$dislikes/youtube_data$likes 

#제목 길이

youtube_data$title_length <- nchar(youtube_data$title) 

#영상설명 길이
youtube_data$description_length <- nchar(youtube_data$description) 

#tag 개수
youtube_data$tags_count <- ifelse(youtube_data$tags=="[None]",0,str_count(youtube_data$tags, fixed('|'))+1) 

#youtube_data$trending_date_format <- as.Date(youtube_data$trending_date) #날짜형으로 변환
#str(youtube_data$trending_date_format)

#publishedAt_format 날짜형으로 변환
youtube_data$publishedAt_format <- as.POSIXct(youtube_data$publishedAt, format = "%Y-%m-%dT%H:%M:%S")

#trending_date 날짜형으로 변환
youtube_data$trending_date_format <- as.POSIXct(youtube_data$trending_date, format = "%Y-%m-%dT%H:%M:%S") 

#테이블 확인
View(youtube_data)

#csv파일로 추출
write.csv(youtube_data, "E:/DataMining/Final_KR_youtube_trending_data.csv")

#다시 불러오기
youtube_data <- read.csv("E:/DataMining/Final_KR_youtube_trending_data.csv")
View(youtube_data)

#---------------------------------------------------------------------------------------------------------------가설 1번 시작

mean_view_count <- summary(youtube_data$view_count)
mean_view_count

#조회수 파이그래프 새로운 컬럼 생성
youtube_data$view_count_group <- ifelse(youtube_data$view_count <=200000, "0~20만",
                                        ifelse(youtube_data$view_count >=200000 & youtube_data$view_count<=500000,"20만~50만",
                                               ifelse(youtube_data$view_count >=500000 & youtube_data$view_count<=1000000, "50만~100만",
                                                      ifelse(youtube_data$view_count >=1000000 & youtube_data$view_count <=5000000, "100만~500만",
                                                             ifelse(youtube_data$view_count >=5000000 & youtube_data$view_count <=10000000, "500만~1000만","1000만 이상")))))

View(youtube_data$view_count_group)


#파이그래프 시각화를 위한 데이터프레임화
x1 <- sum(str_count(youtube_data$view_count_group, "0~20만"))
x2 <- sum(str_count(youtube_data$view_count_group, "20만~50만"))
x3 <- sum(str_count(youtube_data$view_count_group, "50만~100만"))
x4 <- sum(str_count(youtube_data$view_count_group, "100만~500만"))
x5 <- sum(str_count(youtube_data$view_count_group, "500만~1000만"))
x6 <- sum(str_count(youtube_data$view_count_group, "1000만 이상"))


구간 <- c("0~20만", "20만~50만","50만~100만","100만~500만", "500만~1000만","1000만 이상")
구간값 <- c(x1,x2,x3,x4,x5,x6)
상대도수 <- c(x1/2655, x2/2655, x3/2655, x4/2655, x5/2655, x6/2655)
explode <- c(0, 0.1, 0,0,0,0)
                                       
des_frame123 <- data.frame(구간,구간값, 상대도수, explode)
View(des_frame123)                                        
                      
                
#파이그래프로 시각화
des_bp123 <- ggplot(des_frame123 , aes(x="", y=구간값, fill=구간))+
  geom_bar(width=1, stat="identity") +
  coord_polar("y", start=0) +
  geom_text(aes(label=paste0(round(상대도수*100,1),"%")),
            position=position_stack(vjust=0.5)) +
  scale_fill_manual(values=c("#F26760","#F58C86","#FAB5B0","#FCD9D7","#864241","#B33129")) +
  theme_void()
des_bp123

#---------------------------------------------------------------------------------------------------------------가설 1번 끝

#---------------------------------------------------------------------------------------------------------------가설 2번 시작

mean_time2 <- difftime(youtube_data$trending_date_format, youtube_data$publishedAt_format, units = 'hours')
View(mean_time2)

mean_time_cal2 <- mean(mean_time2)
mean_time_cal2

max_time_cal3 <- max(mean_time2)
max_time_cal3

#---------------------------------------------------------------------------------------------------------------가설 2번 끝


#---------------------------------------------------------------------------------------------------------------가설 3번 시작

#------------------------------------설명 파이그래프 그리기
youtube_data$des_logi <- ifelse(youtube_data$description_length==0, "FALSE", "TRUE")
View(youtube_data)

설명_사용_여부 <- c("TRUE", "FALSE")
des_bool_count <- c(sum(str_count(youtube_data$des_logi, "TRUE")),sum(str_count(youtube_data$des_logi, "FALSE")))
설명_상대_도수 <- c(2572/2655, 83/2655)

des_frame <- data.frame(설명_사용_여부, des_bool_count, 설명_상대_도수)
View(des_frame)

#ggplot로 파이그래프 그리기
library(ggplot2)

des_bp <- ggplot(des_frame, aes(x="", y=des_bool_count, fill=설명_사용_여부))+
  geom_bar(width=1, stat="identity", color="white") +
  coord_polar("y", start=0) +
  geom_text(aes(label=paste0(round(설명_상대_도수*100,1),"%")),
            position=position_stack(vjust=0.5)) +
  scale_fill_manual(values=c("#808080","#e74d54")) +
  theme_void()
des_bp

#------------------------------------태그 파이그래프 그리기

#tags_count가 0이면 태그 사용 안함, 그 외엔 사용함
youtube_data$tags_logi <- ifelse(youtube_data$tags_count==0, "FALSE", "TRUE")

태그_사용_여부 <- c("TRUE", "FALSE")
tags_bool_count <- c(sum(str_count(youtube_data$tags_logi, "TRUE")),sum(str_count(youtube_data$tags_logi, "FALSE"))) #태그사용하는 영상 count
태그_상대_도수 <- c(2316/2655, 339/2655)

tags_frame <- data.frame(태그_사용_여부, tags_bool_count, 태그_상대_도수)
View(tags_frame)

#ggplot로 파이그래프 그리기


tags_bp <- ggplot(tags_frame, aes(x="", y=tags_bool_count, fill=태그_사용_여부))+
           geom_bar(width=1, stat="identity", color="white") +
           coord_polar("y", start=0) +
           geom_text(aes(label=paste0(round(태그_상대_도수*100,1),"%")),
                     position=position_stack(vjust=0.5)) +
           scale_fill_manual(values=c("#525252","#e74d54")) +
           theme_void()
tags_bp

#------------------------------------산점도 그리기

# 조회수 2천만 이상의 데이터는 삭제
youtube_data_under2 <- youtube_data%>% filter(view_count<=20000000)

# 댓글 개수 십만 이상의 데이터는 삭제
youtube_data_under_comments <-youtube_data_under2%>% filter(comment_count<=100000)

#조회수 숫자 단위로 수치 나타내는 함수
label_num_view = function(num){
  num_view=function(x){
    new_num= x%/%1000000
    return(paste(new_num,'백만',sep=''))
  }
  return(sapply(num,num_view))
}

#댓글 갯수 숫자 단위로 수치 나타내는 함수
label_num_comment = function(num){
  num_comment=function(x){
    new_num= x%/%100000
    return(paste(new_num,'십만',sep=''))
  }
  return(sapply(num,num_comment))
}

##조회수와 태그개수의 상관관계 분석
ggplot(youtube_data_under2,aes(x=view_count,y=tags_count))+
  geom_point(color="red")+scale_x_continuous(labels=label_num_view)+
  labs(x="조회수",y="태그개수",title="조회수와 태그개수의 상관관계 분석")+
  theme(plot.title=element_text(size=18))

##조회수와 영상 설명 길이의 상관관계 분석
ggplot(youtube_data_under2,aes(x=view_count,y=description_length))+
  geom_point(color="red")+scale_x_continuous(labels=label_num_view)+
  labs(x="조회수",y="영상 설명 길이",title="조회수와 영상 설명 길이의 상관관계 분석")+
  theme(plot.title=element_text(size=18))


#-------------------------------------------------------------히스토그램

#영상 제목 글자 수 평균 및 분포
t<-ggplot(youtube_data, aes(title_length))
t<-t+labs(x="영상 제목 글자 수", y="개수",title="영상 제목 글자 수 평균 및 분포")+theme(plot.title=element_text(size=18))
t +geom_histogram(binwidth=1, fill="blue") #히스토그램 그리기


#영상 태그 개수 평균 및 분포
s<-ggplot(youtube_data, aes(tags_count))
s<-s+labs(x="영상 태그 개수", y="개수",title="영상 태그 개수 평균 및 분포")+theme(plot.title=element_text(size=18))
s +geom_histogram(binwidth=1, fill="orange") #히스토그램 그리기

#영상 설명 글자 수 평균 및 분포
a<-ggplot(youtube_data, aes(description_length))
a<-a+labs(x="영상 설명 글자 수", y="개수",title="영상 설명 글자 수 평균 및 분포")+theme(plot.title=element_text(size=18))
a +geom_histogram(binwidth=20, fill="red") #히스토그램 그리기


#---------------------------------------------------------------------------------------------------------------가설 3번 끝

#---------------------------------------------------------------------------------------------------------------가설 4번 시작

#--------------------------------------------------------- '코로나' 문자열 개수 검색

sum(str_count(youtube_data$title, "코로나")) #제목에서 코로나 키워드 언급 빈도수
  
sum(str_count(youtube_data$tags, "코로나")) #태그에서 코로나 키워드 언급 빈도수
  
sum(str_count(youtube_data$description, "코로나")) #설명에서 코로나 키워드 언급 빈도수

View(WC_result_df) #제목에서 코로나 빈도수 : 30 , official 키워드와 비슷한 크기
View(WC_result_df_Des) #설명에서 코로나 빈도수 : 142, 레전드 키워드와 비슷한 크기
View(WC_result_df_Tags) #태그에서 코로나 빈도수 : 228, instagram 키워드와 비슷한 크기


#-----------------------------------------------------제목(Title) 워드클라우드

buildDictionary(user_dic=data.frame("코로나", rep("ncn", length("코로나"))), replace_usr_dic = T)

buildDictionary(user_dic=data.frame(readLines("E:/DataMining/코로나.txt"),"ncn"))

#제목만 추출한 txt파일 불러오기
WC_Title <- readLines("E:/DataMining/WordCloud_Title.txt")

#사전 초기화
useNIADic()

#특수문자 제거
WC_Title <- str_replace_all(WC_Title, "\\W", " ")
WC_Title[1:10]

#제목에서 명사만 추출
WC_nouns_Title <- extractNoun(WC_Title)
str(WC_nouns_Title)

#명사들로 이루어진 리스트를 돗수분포표 형태로 변환
WC_nouns_Count <- table(unlist(WC_nouns_Title))

#돗수분포표를 데이터 프레임으로 변환
WC_nouns_df <- as.data.frame(WC_nouns_Count, stringsAsFactors = F)

#데이터프레임 컬럼명 변경
WC_nouns_df <- rename(WC_nouns_df, 명사=Var1, 빈도수=Freq)

#한 글자의 경우 명사가 아닌 경우가 많으므로, 제외
WC_result_df <- WC_nouns_df %>% filter(nchar(명사) >= 2) %>% arrange(desc(빈도수))
View(WC_result_df)

#칼라 팔레트 확인
options(repr.plot.width=13, repr.plot.height=13, warn=-1)
display.brewer.all()

#사용할 칼라팔레트 명시
WC_Title_color <- brewer.pal(10, "OrRd")
mypal <- WC_Title_color[5:9]
mypal

#워드클라우드 만들기

#워드클라우드를 생성할 때 마다 동일한 모양으로 생성되도록 시드를 저장
set.seed(1235) 

devtools::install_github("lchiffon/wordcloud2")
library(wordcloud2)

#color_vector사용
colorVec = rep(c('#232B2B', '#DC3D24'), length.out=nrow(demoFreq))

wordcloud2(data = WC_result_df, fontFamily = "나눔고딕", color=colorVec)

#-----------------------------------------------------태그(Tags) 워드클라우드

#태그만 추출한 txt파일 불러오기
WC_Tags <- readLines("E:/DataMining/WordCloud_Tags.txt") 
View(WC_Tags)

#특수문자 제거
WC_Tags <- str_replace_all(WC_Tags, "\\W", " ")
WC_Tags[1:10]

#태그에서 명사만 추출
WC_nouns_Tags <- extractNoun(WC_Tags)
str(WC_nouns_Tags)

#명사들로 이루어진 리스트를 돗수분포표 형태로 변환
WC_nouns_Count_Tags <- table(unlist(WC_nouns_Tags))

#돗수분포표를 데이터 프레임으로 변환
WC_nouns_df_Tags <- as.data.frame(WC_nouns_Count_Tags, stringsAsFactors = F)

#데이터프레임 컬럼명 변경
WC_nouns_df_Tags <- rename(WC_nouns_df_Tags, 명사=Var1, 빈도수=Freq)

#한 글자의 경우 명사가 아닌 경우가 많으므로, 제외
WC_result_df_Tags <- WC_nouns_df_Tags %>% filter(nchar(명사) >= 2) %>% arrange(desc(빈도수))
View(WC_result_df_Tags)

#워드클라우드 만들기

devtools::install_github("lchiffon/wordcloud2")
library(wordcloud2)

#color_vector사용
colorVec = rep(c('#D5212E', '#C62121','#8D0101','#5B0101'), length.out=nrow(demoFreq))

wordcloud2(data = WC_result_df_Tags, fontFamily = "나눔고딕", color=colorVec)


#-----------------------------------------------------설명(Description) 워드클라우드


#태그만 추출한 txt파일 불러오기
WC_Des <- readLines("E:/DataMining/WordCloud_Des.txt") 
View(WC_Des)

#특수문자 제거
WC_Des <- str_replace_all(WC_Des, "\\W", " ")
WC_Des[1:10]

#태그에서 명사만 추출
WC_nouns_Des <- extractNoun(WC_Des)
str(WC_nouns_Des)

#명사들로 이루어진 리스트를 돗수분포표 형태로 변환
WC_nouns_Count_Des <- table(unlist(WC_nouns_Des))

#돗수분포표를 데이터 프레임으로 변환
WC_nouns_df_Des <- as.data.frame(WC_nouns_Count_Des, stringsAsFactors = F)

#데이터프레임 컬럼명 변경
WC_nouns_df_Des <- rename(WC_nouns_df_Des, 명사=Var1, 빈도수=Freq)

#한 글자의 경우 명사가 아닌 경우가 많으므로, 제외
WC_result_df_Des <- WC_nouns_df_Des %>% filter(nchar(명사) >= 2) %>% arrange(desc(빈도수))
View(WC_result_df_Des)

#워드클라우드 만들기

#워드클라우드를 생성할 때 마다 동일한 모양으로 생성되도록 시드를 저장
set.seed(1238) 


#color_vector사용
colorVec = rep(c('#D5212E', '#C62121','#8D0101','#5B0101'), length.out=nrow(demoFreq))

wordcloud2(data = WC_result_df_Des, fontFamily = "나눔고딕", color=colorVec)


#---------------------------------------------------------------------------------------------------------------가설 4번 끝


#---------------------------------------------------------------------------------------------------------------가설 5번 시작

#카테고리 별 인기 동영상 개수
pp <-freq(youtube_data$category_name, plot=T) #각 카테고리에 따른 빈도 추출
category_name <- rownames(pp) #카테고리 이름 컬럼 추가
porpular_cate <- data.frame(category_name,pp) #데이터 프레임 생성
porpular_cate_del <-porpular_cate[-16,] #porpular_cate의 마지막 행(total) 삭제
porpular_cate_del
g <- ggplot(data=porpular_cate_del, aes(x=reorder(category_name,Frequency), y=Frequency, fill=category_name))
g <- g+geom_bar(stat="identity") #막대그래프 그리기
g <- g+coord_flip() #가로그래프로 그리기 위해 x와 y축 바꾸기
g <- g+labs(x="카테고리",y="개수",title="카테고리 별 인기 동영상 개수")+theme(plot.title=element_text(size=18))
g+geom_text(aes(label=Frequency), size=3.5, hjust=1.25, color='#000000')

#---------------------------------------------------------------------------------------------------------------가설 5번 끝

#---------------------------------------------------------------------------------------------------------------가설 6번 시작

#카테고리별 평균 조회수
mean1_dataframe_value <- c(aggregate(youtube_data$view_count, by=list(youtube_data$category_name), FUN = mean))

mean_dataframe <- data.frame(mean1_dataframe_value)
sort(mean_dataframe$mean_view_count, decreasing = T)
View(mean_dataframe)

mean_dataframe <- rename(mean_dataframe, "category_name"="Group.1")
mean_dataframe <- rename(mean_dataframe, "mean_view_count"="x")

mean_dataframe %>% arrange(desc(mean_view_count))

mean_dataframe$mean_view_count <- abs(mean_dataframe$mean_view_count)

g <- ggplot(data=mean_dataframe, aes(x=reorder(category_name, abs(mean_view_count)), y=abs(mean_view_count), fill=category_name))
g <- g+geom_bar(stat="identity") #막대그래프 그리기
g <- g+coord_flip() #가로그래프로 그리기 위해 x와 y축 바꾸기
g <- g+labs(x="카테고리",y="조회수",title="카테고리별 평균 조회수")+theme(plot.title=element_text(size=18))
g+geom_text(aes(label=mean_view_count), size=3.5, hjust=1.25, color='#000000')

#---------------------------------------------------------------------------------------------------------------가설 6번 끝

#(가설 7번은 삭제됨)

#---------------------------------------------------------------------------------------------------------------가설 8번 시작

##조회수와 좋아요/싫어요 간의 상관관계 분석
ggplot(youtube_data_under2,aes(x=view_count,y=likes_dislikes))+
  geom_point(color="red")+scale_x_continuous(labels=label_num_view)+
  labs(x="조회수",y="좋아요/싫어요 비율",title="조회수와 좋아요/싫어요 간의 상관관계 분석")+
  theme(plot.title=element_text(size=18))

##조회수와 댓글 개수 간의 상관관계 분석
ggplot(youtube_data_under_comments, aes(x=view_count, y=comment_count))+
  geom_point(color="red")+scale_x_continuous(labels=label_num_view)+
  #scale_y_continuous(labels=label_num_comment)+
  #coord_trans(x='log10')+
  labs(x="조회수",y="댓글 개수",title="조회수와 댓글 개수 간의 상관관계 분석")+
  theme(plot.title=element_text(size=18))



#------------------------------------히트맵 그리기

install.packages("corrplot")
library(corrplot)
#데이터 전처리 (youtube데이터 파일에서 필요한 값만 가져와서 데이터프레임 생성. youtube데이터 파일을 히트맵 그리는데 필요없는 컬럼까지 통째로 가져오면 실행이 안되기 때문)
coryoutube <- data.frame(youtube_data$view_count,youtube_data$description_length,youtube_data$likes_dislikes,youtube_data$comment_count,youtube_data$tags_count)
coryoutube[is.na(coryoutube)] <-0 #na 값 모두 0으로

youcor<- cor(coryoutube)
round(youcor,2)
corrplot(youcor, method='shade', shade.col=NA, tl.col='black',tl.srt=45)


#---------------------------------------------------------------------------------------------------------------가설 8번 끝

#---------------------------------------------------------------------------------------------------------------가설 9번 시작

#인기 동영상들의 영상 업로드 시간

upload_time<- freq(hour(youtube_data$publishedAt_format,plot=T)) #영상 업로드 시간에 따른 빈도 추출 
time_name <- c("00","01","02","03","04","05","06","07","08","09","10",
               "11","12","13","14","15","16","17","18","19","20","21","22","23") #0~23시 
time_dataframe <- data.frame(time_name,upload_time) #데이터 프레임 생성
time_dataframe_del <-time_dataframe[-25,] #time_dataframe의 마지막행(total) 삭제
time_dataframe_del
p <- ggplot(data=time_dataframe_del, aes(x=time_name, y=Frequency, fill=time_name))
p <- p+geom_bar(stat="identity") #막대그래프 그리기
p <- p+labs(x="시각",y="동영상 개수",title="인기 동영상들의 영상 업로드 시간")+theme(plot.title=element_text(size=18))
p+geom_text(aes(label=Frequency), size=3, vjust=1.15, color='#FFFFFF')

#---------------------------------------------------------------------------------------------------------------가설 9번 끝

#-------------------------------------------------------------------------------------------------------------단어 연관성 시각화
word_title <- readLines("E:/DataMining/WordCloud_Title.txt")#불러오기

lword_title <- str_replace_all(word_title, "\\W", " ") #특수문자 제거

lword_title <- extractNoun(lword_title)

filter1 <- function(x){ #2글자에서 6글자 사이, 한글만
  nchar(x) >= 2 && nchar(x) <= 6
}

filter2 <- function(x){
  Filter(filter1,x)
}

lword_title <- sapply(lword_title, filter2) #단어길이 1이하 또는 5이상인 단어 제거
head(lword_title)

library(arules)

title_tran <- as(lword_title, "transactions") #트랜잭션 생성
View(title_tran)

wordtable_title <- crossTable(title_tran) #교차평 작성

#단어간 연관 규칙 산출/ support: 지지도, 해당 규칙이 얼마나 의미가 있나? 
#/ conf : 신뢰도 사건 A가 발생했을 때, 사건 B가 일어날 확률이 얼마나 높은가?
transrlues_title <- apriori(title_tran, parameter = list(support=0.001, conf=0.02))

inspect(transrlues_title) #연관규칙 생성 결과 조회

rules_title <- labels(transrlues_title, ruleSep= " ") #연관어 시각화

rules_title <- sapply(rules_title, strsplit, " ", USE.NAMES=F) #문자열로 묶인 연관 단어를 행렬 구조로 변경
class(rules_title)

rulemat_title <- do.call("rbind", rules_title) #행단위로 묶어서 행렬로 반환
class(rulemat_title)

library(igraph)

relueg_title <- graph.edgelist(rulemat_title[c(12:59),], directed = F) #{} 제외하고, 연관단어를 vertex형태로 목록 제공

plot.igraph(relueg_title) #최종 그래프로 시각화

plot.igraph(relueg_title, vertex.label=V(relueg_title)$name, vertext.label.cex=1.2, vertex.label.color='black',
            vertext.size=80, vertex.color='orange', vertex.frame.color='orange')

#---------------------------------------------------------------------------------------------------------------------단어 연관성 시각화끝